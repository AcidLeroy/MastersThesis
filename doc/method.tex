\chapter{Methods}
In this chapter we review the basic implementation details of our ViDA
framework. We first demonstrate how we use Lucas-Kanade and Farneback optical
flow algorithms to reduce the feature space to only six 25 bin feature vectors.
With that feature space, we outline how to classify the videos using several
well known machine learning algorithms such as K-nearest neighbors and support
vector machines (SVM). Finally, we cover how we designed this system to be
completely horizontally and vertically scalable on the AWS cloud.


\section{\label{section:vida_oflow} Implementing Optical Flow in ViDA}
In our software, we use two OpenCV library calls, \texttt{goodFeaturesToTrack}
and \\
\texttt{calcOpticalFlowPyrLK} to implement the Lucase-Kanade Pyrmidal optical
flow. The first function is used to find features that can be easily tracked
from one frame to the other using the Shi-Tomasi algorithm \cite{shi1994good}.
The next method then calculates the optical flow between the good points using
the pyramidal implementation of the Lucas-Kanade algorithm
\cite{bouguet2001pyramidal}. Algorithm \ref{alg:lk_flow} outlines the general
program flow for calculating motion vectors in ViDA.

\begin{algorithm}
\caption{Calculating Lucas-Optical Flow from Videos}
\label{alg:lk_flow}
\begin{algorithmic}[1]
\Procedure{CalculateVectors}{$frame1$, $frame2$}
  \If{\text{$track\_points\_initialized$}}
  	\State $opticalflow \gets \texttt{calcOpticalFlowPyrLK}(track\_points, frame1, frame2)$
  \Else
  	\State $track\_points \gets \texttt{goodFeaturesToTrack}(frame1)$
	\State $track\_points\_initialized \gets True$
	\State $optical\_flow \gets  \texttt{CalculateVectors}(frame1, frame2)$
  \EndIf
  \Return $optical\_flow$
\EndProcedure
\end{algorithmic}
\end{algorithm}

The algorithm used in ViDA is similar to Algorithm \ref{alg:lk_flow} but
contains fewer steps since there is no need to get good features to track.
In the C++ software, we also implemented Farneback method. The
Farneback implementation is shown in Algorithm \ref{alg:farneback}.

\begin{algorithm}
\caption{Calculating Farneback Flow from Videos}
\label{alg:farneback}
\begin{algorithmic}[1]
\Procedure{CalculateVectors}{$frame1$, $frame2$}
  \State $optical\_flow \gets \texttt{calcOpticalFlowFarneback}(frame1, frame2)$\\
  \Return $optical\_flow$
\EndProcedure
\end{algorithmic}
\end{algorithm}

As can be seen in \ref{alg:farneback}, we don't need any good features to track
because we are calculating the optical flow globally between frames, rather than
selecting a few features. This has the advantage of tracking optical flow objects
that may fail the Shi-Tomasi method for tracking, but because it is no discriminant
in the features, the resulting motion vectors are dense.


\section{\label{section:comparison}Comparison of Methods}
We implemented the Lucas-Kanade method first in our research because in general,
performance is a concern and, as long as not too many features or
too few features are detected, the Lucas-Kanade algorithm will be faster
\cite{de2015choosing}. Despite this fact, we found that our classifier did
not perform as well on features extracted from the Lucas-Kanade method, as it
did using the Farneback method. Hence most of the results in this thesis
have been calculated with Farneback optical flow unless otherwise specified.

\section{\label{section:feature_extraction}Feature Extraction from Optical Flow}
The \texttt{CalculateVectors} function in both Algorithm \ref{alg:lk_flow} and
\ref{alg:farneback} returns several dense matrices that represent the features
that we can extract from the optical flow output. These features are magnitude,
orientation, x direction and y direction of the optical flow features. These are
ultimately the features that we use to train and classify using an SVM. However,
if we had two $N \times M$ video frames as the input, we now have $4 \times N
\times M$ features. Clearly we have not yet reduced the input feature space.
Thus, based on information that we know \textit{a-priori}, we can reduce our
feature space significantly.

In the case of typing and writing, we know we can expect there to be motion from
one frame to the next. We don't know by how much, but we do know that it is not
zero. Using this knowledge, we can then threshold the optical flow vectors that
we get back from Algorithms \ref{alg:lk_flow} and \ref{alg:farneback}. The
threshold value used was empirically calculated from doing multiple runs on the
AOLME videos. We found we got the best results by only retrieving
optical flow vectors with a magnitude greater than 75\% of the max value. The set
of Equations in \ref{eq:optical_threshold} illustrate this idea.

\begin{align}
  \label{eq:optical_threshold}
  \begin{split}
  \mathbf{V} &= (\mathbf{V_x}, \mathbf{V_y}) \\
  \mathbf{V_m} &=
  \begin{cases}
    1, & \text{if } \|\mathbf{V}\| \geq \max( \|\mathbf{V}\|) \times 0.25 \\
    0, & \text{otherwise}
  \end{cases}
  \end{split}
\end{align}

where $\mathbf{V_x}$ and $\mathbf{V_y}$ are the optical flow vectors in the
x and y directions respectively. $\mathbf{V_m}$ is the bit mask that is
then used to extract the subset of data from each of the dense matrices.

\begin{align}
  \label{eq:subset}
  \begin{split}
  \text{Let: } \\
  \|\mathbf{V\prime}\| &= \|\mathbf{V}\| \circ \mathbf{V_m}\\
  \mathbf{V_x\prime} &= \mathbf{V_x} \circ \mathbf{V_m}\\
  \mathbf{V_y\prime} &= \mathbf{V_y} \circ \mathbf{V_m}\\
  \mathbf{\Phi\prime} &= \mathbf{\Phi} \circ \mathbf{V_m}
\end{split}
\end{align}

Using the optical flow bitmask, $\mathbf{V_m}$, we can then extract features
from each one of our dense matrices using the Hadamard product as shown in
Equation \ref{eq:subset}, where $\|\mathbf{V\prime}\|,
\mathbf{V_x\prime},\mathbf{V_y\prime}, \mathbf{\Phi\prime}$ are subset matrices
for the magnitude, x and y direction and orientation respectively. We have now
reduced the feature space somewhat, but depending on the size of the video and the
amount of entropy per frame pair, we could still have a significant amount of
data to process for classification, this idea is especially true for
Farneback optical flow.

In addition to extracting generic vectors from the video, we also add
geometrical centroids, blob orientation and background motion around the blobs
to the optical flow statistics being used for classification. We implement these
methods to attempt to leverage information that could be useful during
classification. In order to calculate the geometrical centroids and orientations
of each blob, we use some well known algorithms available in OpenCV,
\texttt{connectedComponentsWithStats} and \texttt{findContours}
\cite{itseez2015opencv}. \texttt{connectedComponentsWithStats} is a function
that allows us to compute the centroid for each blob of connected pixels. The
input to this function is our binary mask image, $\mathbf{V_m}$. Once we have
all the connected blobs, we can then calculate the orientation of each one of
those blobs using \texttt{findContours} in combination with with
\texttt{fitEllipse}. The full implementation of this algorithm is outlined in
Appendix \ref{ap:centroids}. The final step is to then dilate each blob, and
then retrieve the magnitude of the optical flow in this region. Appendix
\ref{ap:dilate}. Figure \ref{fig:orient_cent} illustrates the idea of acquiring
the centroid and orientation of the blobs from $\mathbf{V_m}$.

\begin{figure}[h]
  \label{fig:orient_cent}
  \centering
  \includegraphics[width=8cm]{figures/cent_and_orient}
  \caption{Example of orientation measurement on the left, and the centroid
  calculation on the right.}
\end{figure}

When the previous optical flow features have been generated, their values are
then organized into a probability density function (PDF) with 25 bins. That is
to say that each frame pair generates a PDF and that PDF is accumulated for
every subsequent frame in the video sequence. When our software reaches the end
of the video file, a normalized, cumulative distribution function (CDF) is
calculated and output for each vector. So for each input video there will be one
CDF with 25 bins for blob orientation, blob centroid x and y, motion vector
magnitude, motion vector orientation and background motion vector magnitude.
Figure \ref{fig:extract_flow} clearly illustrates this concept.

\begin{figure}[h]
  \label{fig:extract_flow}
  \centering
  \includegraphics[width=14cm]{figures/extract_features_flow}
  \caption{Flow of the extract features program. For every input video, it will
  return a CDF with 25 bins for each of the extracted features from the motion
  vectors}
\end{figure}

Ultimately, these are the features that are then accumulated for multiple AOLME
videos and used for classification.

\section{\label{section:classification}Classifying the Reduced Feature Space}
At this point we now have accumulated a bag of features for videos. The features
that are collected are stored in a comma separated file (csv) that can be read
in by the any of the popular machine learning packages such as those provided
by the R language or Python's SciKit-Learn. The file contains labels that have
filename, centroid x CDF, centroid Y CDF, background motion CDF, motion magnitude
CDF, motion orientation CDF and classification. We can then use an SVM to classify
the features. To validate our results, we use leave-one-out cross validation
to ensure that we have not overfit the data.

\section{\label{section:distributed_processing}Scalable Architecture}
A core principal for a well designed, horizontally scalable application, is
to design it such that it does not contain state \cite{awsbestpractices}.
When state is required, it the software complexity increases substantially and
makes it difficult to distribute the system over a scalable amount of nodes.
However, if the software was designed such that each service can operate and
stand on its own, it is the perfect embarrassingly parallel computing task to
tackle. For this thesis we focus on ensuring that our feature extractor,
as described in Section \ref{section:feature_extraction}, is completely stateless.
This is a design feature that has allowed us the flexibility to scale our
system over as many nodes as are available on the AWS cloud.

\subsection{\label{subsection:architecture_overview}Architecture Overview}
Our system builds upon AWS to create an easy-to-maintain and easy-to-scale
video processing system. We use S3 storage to put small video clips that
have been extracted from our AOLME dataset. These clips are made available to
to all of the processing nodes. The processing nodes communicate with the master
node using Amazon's simple queue service (SQS). Figure \ref{fig:dataflow} illustrates
the basic distributed system design.

\begin{figure}[h]
  \label{fig:dataflow}
  \centering
  \includegraphics[width=\textwidth]{figures/extract_features_dataflow}
  \caption{Dataflow of the distributed video system using AWS components}
\end{figure}

From Figure \ref{fig:dataflow} we see that the first step is to upload
the videos to S3. We keep the videos very small, because as we show in our experiments
section, it takes quit a long time to process large videos therefore there is a
significant benefit to keeping the video chunks relatively small so that many
machines could potentially work on the feature extraction process. The next step
is to place a message on the SQS queue specifying which video to process and
what its classification is. For the purposes of this thesis, we manually place
messages on the queue so that we can control the flow of messages. In
a production system though, we would have the S3 bucket notify the SQS queue that
a new video was uploaded and ready for processing. The third step is the processing
step. In our setup, we create 20 EC2 instances running our feature extractor application.
Each one of these instances polls the SQS queue waiting for a message to arrive.
As soon as one does, it downloads the appropriate video from the S3 bucket,
processes the video, and then places the results on another SQS queue. At this
point, the master node is polling the results queue and collecting the results
into a csv file. Finally, the csv file can be used to train the SVM in the R
code.

\subsection{\label{subsection:master_node}Master Node Configuration}
The master node in our system is responsible for sending out jobs to process and
then coalescing the results from the calculations performed by the slave nodes.
All of these processes are done using the boto3 \cite{boto3} Python  software
development kit (SDK). The core implementation of AWS uses a  representational
state transfer like (RESTful) interface to communicate to all the services that
Amazon offers in a programatic  way, but they also offer several easy-to-use
object oriented libraries written  in several languages to make programming easier
for the end user. The master node
need not be any specific operating system as long as the Python language
can be interpreted on it. In this thesis, we use Ubuntu 14.04 to run our master
node logic, but it could just as well be OS x or any other flavor of linux.

The master node performs several basic tasks. The first of which is to put
messages on the SQS queue.  This is orchestrated by reading
a csv file that consists of an S3 link to a video segment, the classification of
the segment, the SQS queue to which to output the features and finally the
optical flow method to use. An example of the file is show in Table
 \ref{table:message_queue}.

\begin{table}[h]
  \label{table:message_queue}
  \begin{tabular}{ | l | l | l | p{3cm} |}
  \hline
  \textbf{path} & \textbf{classification} & \textbf{sqs\_queue} & \textbf{of\_algorithm}\\ \hline
  aolme/data/typing/seg\_1.mp4 & 1 & feature\_queue & farneback \\ \hline
  aolme/data/notyping/seg\_1.mp4 & 2 & feature\_queue & farneback \\
  \hline
  \end{tabular}
  \caption{Example of data file that use by the master node to place messages on
  the SQS queue. }
\end{table}

From the example data shown in Table \ref{table:message_queue}, we can see that
the nodes have the ability to switch the algorithm as well as associate a
classification from the video. Having the ability to switch method types allows
us to easily benchmark using Lucas-Kanade optical flow versus Farneback.
We also put the output queue in the message so that the slave nodes know to which
queue to place the results of their calculations. This information is also necessary
for the master to know which queue to wait on to collect all the results. Additionally,
if we need more information to be passed to the slave nodes so that they can
effectively do their job, we can easily put that information in the queue with
the message trivially.

Once the master node has sent all the messages to the queue, it then polls
on the queue it placed the messages on to verify that all the messages have been
remove by the slave nodes. This is an important step to validate that the
slave nodes are indeed popping messages off the SQS queue and processing
the videos that are associated with each message. Once this has been validated,
the master node begins to poll on the designated output queue for the results output
from each of the slave nodes. Once all the results have been collected, the master
node places each of the vectors into a comma separated features file.
The pseudo code for the operations performed by the master are show in Algorithm
\ref{alg:master_node}.

\begin{algorithm}
\caption{Master Node Implementation Pseudo-Code}
\label{alg:master_node}
\begin{algorithmic}[1]
  \State $videos\_to\_process \gets \texttt{ReadInputData(input.csv)}$
  \For{\texttt{i = 0; i < len(videos\_to\_process); ++i}}
    \State $sqs\_message \gets \texttt{CreateMessage(videos\_to\_process[i])}$
    \State $output\_queue\_uri \gets videos\_to\_process[i].output\_queue\_uri$
    \State$\texttt{SendSqsMessage(}sqs\_message, sqs\_uri \texttt{)}$
  \EndFor

  \While{$\texttt{MessagesRemainingInQueue(}sqs\_uri \texttt{)} \neq 0$} \Comment{Poll queue every second}
    \State $\texttt{Sleep(1)}$
  \EndWhile

  \While{$\texttt{MessagesRemainingInQueue(}output\_queue\_uri\texttt{)} \neq 0$}
    \State $feature\_vectors \gets \texttt{ReceiveSqsMessage(output\_queue\_uri\texttt{)}}$
    \State $\texttt{Sleep(1)}$
  \EndWhile

  \State \texttt{WriteFeaturesToDisk(} $feature\_vectors$ \texttt{)}

\end{algorithmic}
\end{algorithm}

As we have shown in this section, very little needs to be configured on the master
node other than the ability to run Python and the AWS python utilities. This
makes running our software from almost any type of machine very easy with just a
few setup steps. The master node plays an important role in sending and receiving
the data that the user wishes to process and is an enabling part of our system.
That is to say, it really doesn't matter what software we are running on our
slave nodes, as long as the slave nodes fulfill the contract that we have
defined in our messaging format. This means that we don't necessarily have to
run our C++ extract features program on the slave nodes, but we could be running
any flavor of algorithm we wish with no configuration changes on the master node.
Not only is this setup scalable, but it's highly flexible because of this idea.

\subsection{\label{subsection:slave_node}Slave Node Configuration }
The next very important piece to our innovative architecture is the algorithm
that is run on all the slave nodes. This algorithm simply polls on a single
queue, then once a messages is received, it downloads the the small S3 video
segment, processes it using our feature extraction technique, puts the results
on a queue that it has discovered on the incoming message, deletes the video
locally and then begins polling on the queue again. Algorithm \ref{alg:slave_node}
illustrates this idea clearly.

\begin{algorithm}
\caption{Slave Node Implementation Pseudo-Code}
\label{alg:slave_node}
\begin{algorithmic}[1]

  \While{$True$}
    \State $sqs\_message \gets \texttt{ReceiveMessages(} queue\_name \texttt{)}$ \Comment{Blocking call}
    \State $video\_path \gets \texttt{DownloadS3Video(} sqs\_message.video\_path \texttt{)}$
    \State $features\_cdf \gets \texttt{ExtractFeatures(} video\_path \texttt{)}$ \Comment{Call C++ Code}
    \State $\texttt{SendS3Message(} sqs\_message.output\_queue, features\_cdf \texttt{)}$
    \State $\texttt{DeleteSqsMessage(} sqs\_message \texttt{)}$ \Comment{Remove message from queue}
    \State $\texttt{Sleep(1)}$
  \EndWhile
\end{algorithmic}
\end{algorithm}

We can see that the slave node logic is, like the master node, very simple. We
simply wait for messages to come in from one queue, process the video, and then
output the features onto another queue. However, there is a piece missing from
Algorithm \ref{alg:slave_node} that makes the slave nodes a truly innovative
part of our overall architecture and that is the orchestration and deployment
of our highly refined C++ code.

One of the big hurdles in launching applications that run on a cluster is that
all the nodes on the cluster must be running the same libraries, operating
system,  and versions of the software so that all the answers are returned from
the slaves are repeatable and reliable. In traditional systems, this action was
typically performed by system admin and as a result, you had to rely on third
party packages and libraries that were deployed with the cluster. So if the
software under development needed some updates to a package or some bug fixes,
you were out of luck. You had  to work around those bug fixes and/or write the
updates by hand to get similar  functionality. This is not so with our system.
Using ECS, EC2 and Docker \cite{Merkel:2014:DLL:2600239.2600241}, we  have
developed a system that allows any flavor of linux to be deployed with any
version of software that is required to run on the slave nodes seamlessly. For
example, we developed our C++ code using OpenCV 3.0 and g++4.8 all on Ubuntu
14.04 and built a Docker container that packaged all that software together.
We were then able to deploy our software to an Amazon machine image (AMI) running
an Amazon flavor of Linux that was built for running docker and for communicating
to an ECS cluster. We did all that without configuring a single Linux instance
by hand. And should we choose to roll back to an earlier version of OpenCV or
upgrade our compiler to the latest standard, we could do so by changing the
configuration of our Docker container and our development environment. This
method in no way hinders either vertical or horizontal scalability. With Docker,
we can still pass flags that allow the container to take over the host's GPUs
so that any code written specifically for the GPUs can still be run in a container.


\section{\label{section:auto_deployment}Automatic Deployment of Software and
the Development Process}
An aspect of this thesis that separates us from many of the techniques proposed
in the background section, is the way we have developed our system to be readily
repeatable, easy to use and flexible to allow to future improvements. This is
especially important to UNM's image and video processing and communication lab
iVPCL lab so that future graduate students can leverage the work done in this
thesis to get a head start on future developments of the proposed feature
extraction algorithm and on ViDA's architecture. In this section we cover
several topics that demonstrate that we have done more than just provide an
innovative solution to classifying activities in video, but have also created a
system after which other projects can model themselves. Specifically, we cover
how ViDA's underlying C++ code is developed and how it is automatically and
seamlessly deployed to AWS all the while maintaining a vertically and
horizontally scalable architecture.

\subsection{\label{subsection:opencv_tapi}Vertical Scalability}
Since the iVPCL is strongly geared towards vertically scalable solutions using
FPGAs and GPUs, it is fitting that we should also make the goal of this thesis
to leverage those technologies. To do so, we have developed our software to take
advantage of OpenCV's transparent API known as TAPI. The transparent API is an
enabling technology to be able to seamlessly switch between GPU, CPU and or any
hardware technologies without the software programmer having to select one at
compile time or at run time explicitly. TAPI uses Open Computing Language
(OpenCL) has its underlying technology to achieve significant improvements over
its base algorithm suite. This fundamental technology allows the programmer to
write software for a variety of hardware implementations without being burdened
with implementing the algorithms by hand. For example, the Farneback optical
flow algorithm that is already provided in the OpenCV library can be run easily
on either the GPU or the CPU with almost no extra programming on the programmers
part. This is also a powerful idea for users who want to distribute software to
wide community, but have hardware accelerations that can be added to speed the
software up when the hardware is available on the system. So if the programmer
has attached an accelerated algorithm for computing the discrete radon transform
as demonstrated in \cite{Cesar2014a}, it is completely possible to plug that
implementation into OpenCL and in turn program the abstraction layer into the OpenCV
library. This also means that the horizontally scalable aspect of this thesis
still holds. Although it is optimal to have a cluster of machines with FPGAs
hanging from the PCI express bus, implementing the software in OpenCL gives
users the option to run the code on almost any compute device. This means that
the code can run on machines in AWS or in a local cluster. Furthermore, machines
that have the necessary hardware and are accessible in the lab can perform some
of the heavy lifting before farming out the rest of the data to the slave nodes
on the AWS cloud. So even though the system was also designed with horizontal
scalability in mind, the option of going vertically scalable for certain computations
has been in no way hindered.

\subsection{\label{subsection:cont_integration}Continuous Integration}
Its all too often that software is written and completely forgot about because
the build process is forgotten as soon as the software is completed. A goal of
this thesis was to not let that happen. We accomplish this using a relatively
new software technique called continuous integration. Continuous integration is
the idea that software should be constantly giving developers feedback about the
state of their software to ensure robustness and to have an obvious tool for
developers to use document the build process of the software.

For this thesis, we chose to use an online tool called Travis-CI for our
continuous integration. Travis easily hooks into our Github repository and
automates the build process of our extract features program. The build of our
C++ program consists of compiling and linking against all third party libraries,
running all of our google test unit tests, and then deploying the Docker image
to AWS to used for deployment on the ECS cluster. This tool significantly
unburdens the developer from having to do these steps manually. Continuous
integration also ensures that the unit tests that have been developed for the
software work on the deployed environment. In other words, we develop the
software locally on any flavor of linux,  but there is a chance that any new
changes that we have made to the software do not work in the deployed system.
Travis-CI handles ironing out these details for us so that we always know that
our build is a successful one.

The fact that the continuous integration also pushes our Docker image up to  our
ECS cluster is also huge advantage. This process  ensures that  our Cluster is
always running the latest compiled and unit tested version.  So not only have we
made deployment of our software easy using a Docker  container to package it up,
we've also automated the entire deployment process of our software simply by
pushing our code to our Github repo.

Making the deployment and build of our software automated has guaranteed us
that we will have repeatability in our code and that we have the latest
functioning version running on our compute cluster. Furthermore, if mistakes are
made at the local development level and they are not caught until the developer
has pushed their changes to a Git repo, the automated build system will trigger
a failure and not deploy the system. A key contribution with using the automated
build system is that anyone from anywhere will be able to repeat the experiments
that we have performed in this paper with very little software configuration. We
have essentially frozen the code in a working state. Even if AWS goes away, the
core Docker image is available to be run on any *nix type machine with Docker installed.
So if future users decide that they want to use our extract features
